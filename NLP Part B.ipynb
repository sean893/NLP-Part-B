{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Part B: Spellchecker and Autocorrector Application\n",
    "____________________________\n",
    "Created by: Group 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required libraries for this task.\n",
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import chain\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import wordnet as wn\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Corpus\n",
    "filename = 'metamorphosis_clean.txt'\n",
    "#Add corpus to your working directory\n",
    "\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 100 tradÃ©Â®â€\\xa0Â¥mark! â„¢ Â® Reading Books The Project Gutenberg EBook of Metamorphosis, by Franz Kafka\\nTranslated by David Wyllie.\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.net\\n\\n** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **\\n**     Please follow the copyright guidelines in this file.     **\\n\\nÃŸ\\nTitle: Metamorphosis\\n\\nAuthor: Franz Kafka\\n\\nTranslator: David Wyllie\\n\\nRelease Date: August 16, 2005 [EBook #5200]\\nFirst posted: May 13, 2002\\nLast updated: May 20, 2012\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\\n\\n\\n\\n\\nCopyright (C) 2002 David Wyllie.\\n\\n\\n\\n\\n\\n  Metamorphosis\\n  Franz Kafka\\n\\nTranslated by David Wyllie\\n\\n\\n\\nI\\n\\n\\nOne morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"\\n\", \"\",  text)\n",
    "    text = re.sub(r\"[-()]\", \"\", text)\n",
    "    text = re.sub(r\"\\.\", \" .\", text)\n",
    "    text = re.sub(r\"\\!\", \" !\", text)\n",
    "    text = re.sub(r\"\\?\", \" ?\", text)\n",
    "    text = re.sub(r\"\\,\", \" ,\", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d\\w\\d|\\s\\d+$\", \" \",text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"we'd\", \"we would\", text)\n",
    "    text = re.sub(r'[{}@_*>()\\\\#%+=\\[\\]]','', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text \n",
    "clean_data = []\n",
    "\n",
    "for data in text:\n",
    "    clean_data.append(clean_text(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'a',\n",
       " 'd',\n",
       " 'ã',\n",
       " ' ',\n",
       " 'â',\n",
       " ' ',\n",
       " 'â',\n",
       " ' ',\n",
       " ' ',\n",
       " 'â',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " ' ',\n",
       " 'â',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'â',\n",
       " ' ',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 'd',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'b',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'j',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " ' ',\n",
       " 'g',\n",
       " 'u',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " 'g',\n",
       " ' ',\n",
       " 'e',\n",
       " 'b',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'p',\n",
       " 'h',\n",
       " 'o',\n",
       " 's',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " ' ',\n",
       " 'b',\n",
       " 'y',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'a']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(sent):  \n",
    "    \"\"\"Parsing the sentence to corrected and original and storing in the dictionary.\"\"\"\n",
    "    loriginal = []\n",
    "    lcorrected = []\n",
    "    lcorr = []\n",
    "    indexes = []\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in sent:\n",
    "        if '|' in i:\n",
    "            # Splitting the sentence on '|'\n",
    "            str1 = i.split('|')\n",
    "            # Previous word to '|' is storing in loriginal list.\n",
    "            loriginal.append(str1[0])\n",
    "            # Next word to '|' is storing in lcorrected list.\n",
    "            lcorrected.append(str1[1])\n",
    "            #Noting down the index of error.\n",
    "            indexes.append(cnt)\n",
    "        \n",
    "        else:\n",
    "            # If there is no '|' in sentence, sentence is stored in loriginal and lcorrected as it is.\n",
    "            loriginal.append(i)\n",
    "            lcorrected.append(i)\n",
    "        cnt = cnt+1\n",
    "        \n",
    "    #Loading to loriginal, lcorrected and index list to dictionary.      \n",
    "    dictionary = {'original': loriginal, 'corrected': lcorrected, 'indexes': indexes}\n",
    "    \n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d96fc0599f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocessing():\n",
    "    \"\"\"Loading the data from 'holbrook.txt' and passing to parsing function to get parssed sentences. \n",
    "    Returning the whole dictionary as data.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Reading the txt file\n",
    "    text_file = open(\"metamorphosis_cleant\", \"r\")\n",
    "    lines = []\n",
    "    for i in text_file:\n",
    "        lines.append(i.strip())\n",
    "    \n",
    "    # Word tokenizing the sentences\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in lines]\n",
    "    \n",
    "    # Calling a parse function to get corrected, original sentences.\n",
    "    for sent in sentences:\n",
    "        data.append(parsing(sent))\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "##### https://www.languagetool.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
=======
>>>>>>> 344f837d7b13894d069daa33f5aee7144a806389
    "### 1. Data PreProcessing\n",
    "Data preprocessing stages are split into the following parts:\n",
    "+ #### Tokenization of Words\n",
    "+ #### Case Normalization\n",
    "+ #### Removing the following:\n",
    "  - Punctuation\n",
    "  - Stop Words\n",
    "  - Numeric Characters\n",
    "  - Special Characters\n",
    "  - Accented Characters\n",
    "\n",
    "+ #### Stemming and Lemmatization?\n",
    "  \n",
    "<u><i>More Text Cleaning Considerations:</i></u>\n",
    "\n",
    "- Handling large documents and large collections of text documents that do not fit into memory.\n",
    "- Extracting text from markup like HTML, PDF, or other structured document formats.\n",
    "- Transliteration of characters from other languages into English.\n",
    "- Decoding Unicode characters into a normalized form, such as UTF8.\n",
    "- Handling of domain specific words, phrases, and acronyms.\n",
    "- Handling or removing numbers, such as dates and amounts.\n",
    "- Locating and correcting common typos and misspellings.\n",
    "- Resolve contractions for casual text.\n",
    "\n",
    "-----------------------------------------\n",
    "### 4. Design Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\tYour application must be able to find the spelling errors and suggest a few words to the user to modify the text.\n",
    "\n",
    "c)\tThe spelling errors that need to be addressed by your system are:\n",
    "\n",
    "i.\tNon-words (wrong spelling, where the word does not exist)\n",
    "\n",
    "ii.\tReal-words (wrong spelling due to wrong context, but the misspelt word does exist)\n",
    "    - Grammatical errors, typos e.t.c\n",
    "\n",
    "d)\tThe techniques used for the detection of the spelling errors must include: <body>\n",
    "  <p style=\"color:rgb(255,0,0);\"> - Bigrams</p>\n",
    "     <p style=\"color:rgb(255,0,0);\"> - Minimum Edit Distance,</p>\n",
    "     <p style=\"color:rgb(255,0,0);\">- Other suitable popular techniques used in NLP</p>\n",
    "   </body>\n",
    "\n",
    "<p>e)\tProvide the following functionality in your application: </p>\n",
    "<p>   Ability to show a sorted list of all words in the corpus with the facility of exploring the list and search for a     specific word.</p>\n",
    "\n",
    "\tAbility to highlight the misspelled words, and right click to suggest the correct words (with their minimum edit     distance from the wrong word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Corpus and Importing Packages"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 2,
>>>>>>> 344f837d7b13894d069daa33f5aee7144a806389
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Corpus\n",
    "filename = 'metamorphosis_clean.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "\n",
    "# import packages\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import chain\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import wordnet as wn\n",
    "import string\n",
    "import unicodedata\n",
    "import heapq                               \n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization of Words"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', '100', 'tradÃ©Â®â€', 'Â¥mark!', 'â„¢', 'Â®', 'Reading', 'Books', 'The', 'Project', 'Gutenberg', 'EBook', 'of', 'Metamorphosis,', 'by', 'Franz', 'Kafka', 'Translated', 'by', 'David', 'Wyllie.', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever.', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.net', '**', 'This', 'is', 'a', 'COPYRIGHTED', 'Project', 'Gutenberg', 'eBook,', 'Details', 'Below', '**', '**', 'Please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file.', '**', 'ÃŸ', 'Title:', 'Metamorphosis', 'Author:', 'Franz', 'Kafka', 'Translator:', 'David', 'Wyllie', 'Release', 'Date:', 'August', '16,', '2005', '[EBook', '#5200]', 'First', 'posted:', 'May', '13,', '2002', 'Last', 'updated:', 'May', '20,', '2012', 'Language:', 'English', '***', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'METAMORPHOSIS', '***', 'Copyright', '(C)', '2002', 'David', 'Wyllie.', 'Metamorphosis', 'Franz', 'Kafka', 'Translated', 'by', 'David', 'Wyllie', 'I', 'One', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"What\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small,', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls.', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', '-', 'Samsa', 'was', 'a', 'travelling', 'salesman', '-', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice,', 'gilded', 'frame.', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright,', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards', 'the', 'viewer.', 'Gregor', 'then', 'turned', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather.', 'Drops', 'of', 'rain', 'could', 'be', 'heard', 'hitting', 'the', 'pane,', 'which', 'made', 'him', 'feel', 'quite', 'sad.', '\"How', 'about', 'if', 'I', 'sleep', 'a', 'little', 'bit', 'longer', 'and', 'forget', 'all', 'this', 'nonsense\",', 'he', 'thought,', 'but', 'that', 'was', 'something', 'he', 'was', 'unable', 'to', 'do', 'because', 'he', 'was', 'used', 'to', 'sleeping', 'on', 'his', 'right,', 'and', 'in', 'his', 'present', 'state', \"couldn't\", 'get', 'into', 'that', 'position.', 'However', 'hard', 'he', 'threw', 'himself', 'onto', 'his', 'right,', 'he', 'always', 'rolled', 'back', 'to', 'where', 'he', 'was.', 'He', 'must', 'have', 'tried', 'it', 'a', 'hundred', 'times,', 'shut', 'his', 'eyes', 'so', 'that', 'he', \"wouldn't\", 'have', 'to', 'look', 'at', 'the', 'floundering', 'legs,', 'and', 'only', 'stopped', 'when', 'he', 'began', 'to', 'feel', 'a', 'mild,', 'dull', 'pain', 'there', 'that', 'he', 'had', 'never', 'felt', 'before.', '\"Oh,', 'God\",', 'he', 'thought,', '\"what', 'a', 'strenuous', 'career', 'it', 'is', 'that', \"I've\", 'chosen!', 'Travelling', 'day', 'in', 'and', 'day', 'out.', 'Doing', 'business', 'like', 'this', 'takes', 'much', 'more', 'effort', 'than', 'doing', 'your', 'own', 'business', 'at', 'home,', 'and', 'on', 'top', 'of', 'that', \"there's\", 'the', 'curse', 'of', 'travelling,', 'worries', 'about', 'making', 'train', 'connections,', 'bad', 'and', 'irregular', 'food,', 'contact', 'with', 'different', 'people', 'all', 'the', 'time', 'so', 'that', 'you', 'can', 'never', 'get', 'to', 'know', 'anyone', 'or', 'become', 'friendly', 'with', 'them.', 'It', 'can', 'all', 'go', 'to', 'Hell!\"', 'He', 'felt', 'a', 'slight', 'itch', 'up', 'on', 'his', 'belly;', 'pushed', 'himself', 'slowly', 'up', 'on', 'his', 'back', 'towards', 'the', 'headboard', 'so', 'that', 'he', 'could', 'lift', 'his', 'head', 'better;', 'found', 'where', 'the', 'itch', 'was,', 'and', 'saw', 'that', 'it', 'was', 'covered', 'with', 'lots', 'of', 'little', 'white', 'spots', 'which', 'he', \"didn't\", 'know', 'what', 'to', 'make', 'of;', 'and', 'when', 'he', 'tried', 'to', 'feel', 'the', 'place', 'with', 'one', 'of', 'his', 'legs', 'he', 'drew', 'it', 'quickly', 'back', 'because', 'as', 'soon', 'as', 'he', 'touched', 'it', 'he', 'was', 'overcome', 'by', 'a', 'cold', 'shudder.', 'He', 'slid', 'back', 'into', 'his', 'former', 'position.', '\"Getting', 'up', 'early', 'all', 'the', 'time\",', 'he', 'thought,', '\"it', 'makes', 'you', 'stupid.', \"You've\", 'got', 'to', 'get', 'enough', 'sleep.', 'Other', 'travelling', 'salesmen', 'live', 'a', 'life', 'of', 'luxury.', 'For', 'instance,', 'whenever', 'I', 'go', 'back', 'to', 'the', 'guest', 'house', 'during', 'the', 'morning', 'to', 'copy', 'out', 'the', 'contract,', 'these', 'gentlemen', 'are', 'always', 'still', 'sitting', 'there', 'eating', 'their', 'breakfasts.', 'I', 'ought', 'to', 'just', 'try', 'that', 'with', 'my', 'boss;', \"I'd\", 'get', 'kicked', 'out', 'on', 'the', 'spot.', 'But', 'who', 'knows,', 'maybe', 'that', 'would', 'be', 'the', 'best', 'thing', 'for', 'me.', 'If', 'I', \"didn't\", 'have', 'my', 'parents', 'to', 'think', 'about', \"I'd\", 'have', 'given', 'in', 'my', 'notice', 'a', 'long', 'time', 'ago,', \"I'd\", 'have', 'gone', 'up', 'to', 'the', 'boss', 'and', 'told', 'him', 'just', 'what', 'I', 'think,', 'tell', 'him', 'everything', 'I', 'would,', 'let', 'him', 'know', 'just', 'what', 'I', 'feel.', \"He'd\", 'fall', 'right', 'off', 'his', 'desk!', 'And', \"it's\", 'a', 'funny', 'sort', 'of', 'business', 'to', 'be', 'sitting', 'up', 'there', 'at', 'your', 'desk,', 'talking', 'down', 'at', 'your', 'subordinates', 'from', 'up', 'there,', 'especially', 'when', 'you', 'have', 'to', 'go', 'right', 'up', 'close', 'because', 'the', 'boss', 'is', 'hard', 'of', 'hearing.', 'Well,', \"there's\", 'still', 'some', 'hope;', 'once', \"I've\", 'got', 'the', 'money', 'together', 'to', 'pay', 'off', 'my', \"parents'\", 'debt', 'to', 'him', '-', 'another', 'five', 'or', 'six', 'years', 'I', 'suppose', '-', \"that's\", 'definitely', 'what', \"I'll\", 'do.', \"That's\", 'when', \"I'll\", 'make', 'the', 'big', 'change.', 'First', 'of', 'all', 'though,', \"I've\", 'got', 'to', 'get', 'up,', 'my', 'train', 'leaves', 'at', 'five.\"', 'And', 'he', 'looked', 'over', 'at', 'the', 'alarm', 'clock,', 'ticking', 'on', 'the', 'chest', 'of', 'drawers.', '\"God', 'in', 'Heaven!\"', 'he', 'thought.', 'It', 'was', 'half', 'past', 'six', 'and', 'the', 'hands', 'were', 'quietly', 'moving', 'forwards,', 'it', 'was', 'even', 'later', 'than', 'half', 'past,', 'more', 'like', 'quarter', 'to', 'seven.', 'Had', 'the', 'alarm', 'clock', 'not', 'rung?', 'He', 'could', 'see', 'from', 'the', 'bed', 'that', 'it', 'had', 'been', 'set', 'for', 'four', \"o'clock\", 'as', 'it', 'should', 'have', 'been;', 'it', 'certainly', 'must', 'have', 'rung.', 'Yes,', 'but', 'was', 'it', 'possible', 'to', 'quietly', 'sleep', 'through', 'that', 'furniture-rattling', 'noise?', 'True,', 'he', 'had', 'not', 'slept', 'peacefully,', 'but', 'probably', 'all', 'the', 'more', 'deeply', 'because', 'of', 'that.', 'What', 'should', 'he', 'do', 'now?', 'The', 'next', 'train', 'went', 'at', 'seven;', 'if', 'he', 'were', 'to', 'catch', 'that', 'he', 'would', 'have', 'to', 'rush', 'like', 'mad', 'and', 'the', 'collection', 'of', 'samples', 'was', 'still', 'not', 'packed,', 'and', 'he', 'did', 'not', 'at', 'all', 'feel', 'particularly', 'fresh', 'and', 'lively.', 'And', 'even', 'if', 'he', 'did', 'catch', 'the', 'train']\n"
     ]
    }
   ],
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
>>>>>>> 344f837d7b13894d069daa33f5aee7144a806389
   "source": [
    "# split into words by white space\n",
    "words = text.split()\n",
    "\n",
    "# split based on words only\n",
    "\n",
    "words = re.split(r'\\W+', text)\n",
    "\n",
    "# split into words by white space\n",
    "words = text.split()\n",
    "#print(words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text normalization - convert to lower case\n",
    "nor_words = [word.lower() for word in words]\n",
    "#print(nor_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from each word\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped_words = [w.translate(table) for w in nor_words]\n",
    "#print(stripped_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "no_st_words = [w for w in stripped_words if not w in stop_words]\n",
    "#print(no_st_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Numeric Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove numeric characters\n",
    "no_numbers = ' '.join(c for c in no_st_words if not c.isdigit())\n",
    "#print(no_numbers[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tradãââ âmark â â reading books project gutenberg ebook metamorphosis franz kafka translated david w\n"
     ]
    }
   ],
   "source": [
    "# function to remove special characters\n",
    "def remove_s_c(no_numbers):\n",
    "    # define the pattern to keep\n",
    "    rem = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s\\w+)]' \n",
    "    return re.sub(rem, '',no_numbers)\n",
    " \n",
    "# calling the function\n",
    "no_sc_words = remove_s_c(no_numbers)\n",
    "\n",
    "print(no_sc_words[:100])\n",
    "\n",
    "# resulting in double spaces after removing special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tradaaa amark a a reading books project gutenberg ebook metamorphosis franz kafka translated david w\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# function to remove accented characters\n",
    "def remove_a_c(no_sc_words):\n",
    "    new_text = unicodedata.normalize('NFKD', no_sc_words).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "# call function\n",
    "no_ac_words = remove_a_c(no_sc_words)\n",
    "no_ws_words = (\" \".join(no_ac_words.split()))\n",
    "\n",
    "print(no_ac_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trademark reading books project gutenberg ebook metamorphosis franz kafka translated david wyllie eb\n"
     ]
    }
   ],
   "source": [
    "no_ws_words = (\" \".join(no_ac_words.split()))\n",
    "\n",
    "print(no_ws_words[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do List\n",
    "\n",
    "#1. Expand Contractions\n",
    "#2. Create Dictionary\n",
    "#3. Add Unigrams / Bigrams\n",
    "#4. Check repeatition / unnecessary imported libraries\n",
    "#5. Create Copy of File After Every Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
